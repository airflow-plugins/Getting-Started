{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Analytics in Airflow 101."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Overview: Hooks and Operators.\n",
    "The hook will contain all code needed to manage the connection, while the operator will focus on using the connection\n",
    "to execute a task\n",
    "\n",
    "This leaves the DAG file itself as close to a config as possible:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before any code is written, the Google Analytics connection information needs to be accessible to Airflow\n",
    "\n",
    "### Configure the connections in the Airflow connections panel.\n",
    "![connections](img/ucg_connections.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new connection with the name that will be referenced in the DAG\n",
    "![new_connection](img/ucg_config_connections.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Astronomer version of the google-analytics hook is configured it work with the json file put inside of \"client_secret\" in the Extras field:\n",
    "\n",
    "![extras_field](img/ucg_extras_field.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing the DAG file:\n",
    "\n",
    "The DAG file itself should be as close to a config file as possible, simply importing Operators and setting connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from uncommon_good_ga.py: - full file:\n",
    "# /base_workflow/dags/uncommon_goods_ga_dag.py\n",
    "\n",
    "## Set imports.\n",
    "from datetime import datetime, timedelta\n",
    "from airflow import DAG\n",
    "from airflow.operators.dummy_operator import DummyOperator\n",
    "from plugins.google_analytics_plugin.operators.google_analytics_reporting_to_s3_operator import GoogleAnalyticsReportingToS3Operator\n",
    "\n",
    "# TODO: UCG specific credentials:\n",
    "s3_bucket = 'astronomer-workflows-dev'\n",
    "s3_conn_id = 'astronomer-s3'\n",
    "\n",
    "time_string = '{{ ts_nodash }}'\n",
    "google_analytics_conn_id = 'google_analytics_connection'\n",
    "\n",
    "# TODO: Schedule\n",
    "end_date = datetime.today()\n",
    "start_date = end_date - timedelta(days=6)\n",
    "\n",
    "# UCG viewid.\n",
    "view_id = '120725274'\n",
    "\n",
    "default_args = {\n",
    "    # TODO: UCG SPECIFICS:\n",
    "    'start_date': datetime(2018, 3, 20, 0, 0),\n",
    "    'email': ['l5t3o4a9m9q9v1w9@astronomerteam.slack.com'],\n",
    "    'email_on_failure': True,\n",
    "    'email_on_retry': False,\n",
    "    'retries': 0,\n",
    "}\n",
    "# TODO: Naming convention.\n",
    "dag = DAG(\n",
    "    'core_reporting_test_one',\n",
    "    schedule_interval='@daily',\n",
    "    default_args=default_args,\n",
    "    catchup=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now to define the work that's going to get done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from uncommon_good_ga.py: - full file:\n",
    "# /base_workflow/dags/uncommon_goods_ga_dag.py\n",
    "\n",
    "# Lets define the reports needed here:\n",
    "\n",
    "# These are just some basic core reporting reports.\n",
    "pipelines = [\n",
    "    {\n",
    "        'name': 'demographics',\n",
    "        'dimensions': [\n",
    "            {'name': 'ga:date'},\n",
    "            {'name': 'ga:userAgeBracket'},\n",
    "            {'name': 'ga:userGender'}\n",
    "        ],\n",
    "        'metrics': [\n",
    "            {'expression': 'ga:sessions'}\n",
    "        ],\n",
    "\n",
    "        # TODO: Destination schema.\n",
    "        'schema': [\n",
    "            {}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'name': 'date_sessions',\n",
    "        'dimensions': [\n",
    "            {'name': 'ga:date'},\n",
    "        ],\n",
    "        'metrics': [\n",
    "            {'expression': 'ga:sessions'}\n",
    "        ],\n",
    "\n",
    "        # TODO: Destination schema.\n",
    "        'schema': [\n",
    "            {}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'name': 'medium_source',\n",
    "        'dimensions': [\n",
    "            {'name': 'ga:medium'},\n",
    "            {'name': 'ga:source'},\n",
    "        ],\n",
    "        'metrics': [\n",
    "            {'expression': 'ga:sessions'},\n",
    "            {'expression': 'ga:avgTimeOnPage'},\n",
    "            {'expression': 'ga:avgTimeOnPage'},\n",
    "        ],\n",
    "\n",
    "        # TODO: Destination schema.\n",
    "        'schema': [\n",
    "            {}\n",
    "        ]\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the DAG itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from uncommon_good_ga.py: - full file:\n",
    "# /base_workflow/dags/uncommon_goods_ga_dag.py\n",
    "\n",
    "with dag:\n",
    "\n",
    "    start = DummyOperator(task_id='start')\n",
    "\n",
    "    for pipeline in pipelines:\n",
    "        google_analytics = GoogleAnalyticsReportingToS3Operator(\n",
    "            task_id='ga_reporting_{endpoint}_to_s3'.format(\n",
    "                endpoint=pipeline['name']),\n",
    "            google_analytics_conn_id=google_analytics_conn_id,\n",
    "            view_id=view_id,\n",
    "            since=execution_date,\n",
    "            until=next_execution_date,\n",
    "            sampling_level='LARGE',\n",
    "            dimensions=pipeline['dimensions'],\n",
    "            metrics=pipeline['metrics'],\n",
    "            page_size=100,\n",
    "            include_empty_rows=True,\n",
    "            s3_conn_id=s3_conn_id,\n",
    "            s3_bucket=s3_bucket,\n",
    "            s3_key='ucg_ga_reporting_{endpoint}_{time_string}'.format(\n",
    "                endpoint=pipeline['name'], time_string=time_string)\n",
    "        )\n",
    "\n",
    "\n",
    "        start >> google_analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Full file: /base_workflow/dags/ga_dag.py__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This DAG will look like:\n",
    "![new_connection](img/ucg_dag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All additions (downstream file manipulations will) will be dependent on first the GoogleAnalyticstoS3 operator sucessfully getting the data.\n",
    "\n",
    "Each of the objects in the pipelines dictionary in the DAG file is put into a different file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How it works:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The work that needs to get done is defined in the Operator, which actually executes the request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These get fed into the Google Analytics Operator:\n",
    "# full-file: /baseworkflows/plugins/google_analytics_plugin/operators/google_analytics_reporting_to_s3_operator.py\n",
    "\n",
    "# operators execute the execute() function. \n",
    "\n",
    "# Line 92-110.\n",
    "def execute(self, context):\n",
    "    \n",
    "        # Import hooks.\n",
    "        ga_conn = GoogleAnalyticsHook(self.google_analytics_conn_id)\n",
    "        s3_conn = S3Hook(self.s3_conn_id)\n",
    "        \n",
    "        # Check for formatting.\n",
    "        try:\n",
    "            since_formatted = datetime.strptime(self.since, '%Y-%m-%d %H:%M:%S').strftime('%Y-%m-%d')\n",
    "        except:\n",
    "            since_formatted = str(self.since)\n",
    "        try:\n",
    "            until_formatted = datetime.strptime(self.until, '%Y-%m-%d %H:%M:%S').strftime('%Y-%m-%d')\n",
    "        except:\n",
    "            until_formatted = str(self.until)\n",
    "            \n",
    "        # Make request.\n",
    "        report = ga_conn.get_analytics_report(self.view_id,\n",
    "                                              since_formatted,\n",
    "                                              until_formatted,\n",
    "                                              self.sampling_level,\n",
    "                                              self.dimensions,\n",
    "                                              self.metrics,\n",
    "                                              self.page_size,\n",
    "                                              self.include_empty_rows)\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full-File: /baseworkflows/plugins/google_analytics_plugin/operators/google_analytics_reporting_to_s3_operator.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operators use hooks to interact with the external systems involved in the task they're trying to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# full-file: /baseworkflows/plugins/google_analytics_plugin/hooks/google_analytics_hook.py\n",
    "# Line 101-132 - the hook takes the config and provides an interface to interact with the analytics api.\n",
    "# It doesn't determine what actually gets done - just provides a method to do it.\n",
    "\n",
    "# Note here to integrate this with MCF funnels.\n",
    "\n",
    "def get_analytics_report(self,\n",
    "                             view_id,\n",
    "                             since,\n",
    "                             until,\n",
    "                             sampling_level,\n",
    "                             dimensions,\n",
    "                             metrics,\n",
    "                             page_size,\n",
    "                             include_empty_rows):\n",
    "\n",
    "        analytics = self.get_service_object(name='reporting')\n",
    "\n",
    "        reportRequest = {\n",
    "            'viewId': view_id,\n",
    "            'dateRanges': [{'startDate': since, 'endDate': until}],\n",
    "            'samplingLevel': sampling_level or 'LARGE',\n",
    "            'dimensions': dimensions,\n",
    "            'metrics': metrics,\n",
    "            'pageSize': page_size or 1000,\n",
    "            'includeEmptyRows': include_empty_rows or False\n",
    "        }\n",
    "\n",
    "     \n",
    "        response = (analytics.\n",
    "                    reports().\n",
    "                    batchGet(body={'reportRequests': [reportRequest]}).\n",
    "                    execute())\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full-File: /baseworkflows/plugins/google_analytics_plugin/hooks/google_analytics_hook.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
